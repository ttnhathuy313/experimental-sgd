# Question 1:

## Done:

- [x] SGD

- [x] Momentum

- [x] Nesterov

- [x] Adam

- [x] Autodiff - Avaiable to compute both gradient and hessian

- [x] Inverse matrices - Use package numpy.linalg

- [x] Existing code from thầy Hiếu for backtracking
 
## TODO:

- [ ] Choose a fixed algorithm, or come up with a strategy to use combinations.

- [ ] Hyperparams (step size, optimizer hyperparams,...)

- [ ] Any needs for other optimizers, line search, adaptive step size,...?

- [ ] Test - Double-check?

- [ ] Anything else?

## Files:

- f_optimize.py: containing autodiff, optimizers, line search, main optimization

- optimProjTest: test file with common functions (in-class, assignments)
